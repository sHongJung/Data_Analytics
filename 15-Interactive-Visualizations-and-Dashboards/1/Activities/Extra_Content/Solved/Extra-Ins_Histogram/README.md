# Instructor Guidelines and Tips

* Open up [index.html](./index.html) and [plots.js](./plots.js)

* Point out that the data set generating the bar chart is "small", in the sense that there aren't many categories defining the x-axis.

  * Point out that larger data sets don't have this property.

  * **Motivate** by describing the much bigger data set generated by tracking the total number of orders for _any_ cocktail, aggregated over _every_ bar in Manhattan.

  * Point out that a bar chart of this data would be easy to generate, but visually noisy.

* Prompt **discussion** by asking students to brainstorm ways around this problem.

  * In particular, encourage discussions about _categorizing the data_ before plotting it.

* Point out that, to solve the above problem of "too many drinks", we should consider _categories of cocktails_ rather than individual cocktails.

  * For example, we might consider 10 Mai Tais and 10 Daquiris in terms of a _single_ count and category: 20 Rum Cocktails.

* Remind students that this is useful because it forces us to identify and exploit patterns in our data, and because it "smooths"  the initial data set.

* Explain that the categories that we use to build histograms are called **bins**.

* Open up the [Plotly Histogram documentation](https://plot.ly/javascript/histograms/), and briefly talk through the first and second charts on the page.

  * Explain that the x-axis of the histogram is in terms of _bins_, or categories.

  * Explain that the y-axis plots _frequency_, or the number of times a given value appears in each bin.

* Take a moment to illustrate the concept manually, by creating and binning a (small) list of numbers by hand.

  ![bins.png](../../../Images/bins.png)

* Point out that a bar chart built with the raw data would be relatively uninformative and noisy.

  * Point out that first _grouping_ the data like this allows us to identify an interesting pattern that the raw data doesn't immediately suggest: The numbers are uniformly distributed with respect to the intervals we chose as our bins!

* Explain that there are numerous algorithms for identifying and evaluating optimal bin count, boundaries, etc., but that the libraries we use will typically handle these details on our behalf.

  * Reassure students that this is the case with Plotly.

* Point out that histograms are a powerful visual tool for identifying potential outliers and anomalies in a data set.

  [Identifying outliers with a histogram.](http://mathworld.wolfram.com/images/eps-gif/OutlierHistogram_1000.gif)

* Point out that a logical next step is deriving techniques for _removing_ the outliers suggested by the histogram.

  * Explain that, in order to do this, we must first review **percentiles**; **quartiles**; and **i**nter**q**aurtile **r**ange (IQR).

- - -

* Remind students that the **_n_th percentile** of a data set is the number below which _n_ percent of the data falls.

  * Remind students that the median is the 50th percentile: Half of the data lies below the median, half lies above.

  * Remind students that the lower quartile is the 25th percentile: A quarter of the data lies below it.

    * Equivalently, point out that the lower quartile is the median of the left half of the (sorted!) data, e.g.: `lower_quartile = median(data[0:median(data)])`

  * Remind students that the upper quartile is the 75th percentile: A quarter of the data lies below it.

    * Equivalently, point out that the upper quartile is the median of the right half of the (sorted!) data, e.g.: `upper_quartile = median(data[median(data):len(data)])`

  * Remind students that the **i**nter**q**uartile **r**ange is the simple difference between the upper and lower quartiles: `iqr = upper_quartile - lower_quartile`.

* Explain that a common heuristic when analyzing data is to consider any point that falls more than `1.5 * iqr` _above_ the `upper_quartile` or _below_ the `lower_quartile`  an **outlier**.

  * Explain that the interval defined by the endpoints: `(lower_quartile - iqr * 1.5, upper_quartile + iqr * 1.5)` defines a region called the **inner fence**.

  * Explain that points beyond a data set's inner fence are often called **mild outliers**.

  * Explain that the interval defined by the endpoints: `(lower_quartile - iqr * 3, upper_quartile + iqr * 3)` defines a region called the **outer fence**.

  * Explain that points beyond a data set's inner fence are often called **extreme outliers**.

* Remind students that, while outliers are often due to bad data, **they should _not_ be discarded without careful consideration**.

  * Before removing outliers, consider [where they come from, and "whether they are likely to continue to appear"](http://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm).

- - -

* Finally, explain that we will review some core JavaScript concepts to enable us to explore the above ideas in the next activity.

* Review the following relevant programming techniques before proceeding:

  * To create a copy of an array, use `concat`: `const copy = original.concat();`

  * To sort an array, call `sort`, and pass the below compare function. Remind students that `sort` operates in-place.

  ```js
  // @Live
  function compare (first, second) {
    return first - second;
  }
  ```

  * Remind students about the syntax and semantics of `filter`.

* Encourage students to read about the `xbins` and `size` properties of `trace`.

* Encourage students to read about the `bargap` property of `layout`.
